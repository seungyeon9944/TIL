## AI (Artificial Intelligence)
주어진 환경/데이터를 **인지/학습/추론**을 통해 **목표 달성**을 하도록 **예측/행동 선택/계획**하는 시스템

## ML (Machine Learning)
AI 범주 내에서 **데이터로부터 학습**하여 목적을 달성하는 접근 방법론

## DL (Deep Learning)
ML 범주 내에서 **신경망 (Neural Network)** 함수를 사용한 학습 방법론

---

AI-ML (ML이 아닌 AI시스템)의 예 : 규칙 기반 시스템이나 휴리스틱 기반 (최적화) 알고리즘

---
  
ML은 데이터에서 규칙을 학습하기 때문에 데이터의 분포와 관계가 머신러닝의 학습 결과를 결정

### Feature (피처, 특성)
- 모델이 예측에 사용하는 입력정보
- 예측, 판단의 근거/단서

### Label (라벨, 목표값)
- 모델이 예측하려는 정답
- 학습의 목표값
---

### 1D 피쳐 기반 학습 (단일 피쳐 학습)
Feature가 하나일 때 머신러닝이 학습하는 가장 단순한 형태
ex) Income = 𝑓*(Years of Education) + εi
- Years of Education : 피쳐
- Income : 라벨
- 𝑓* : 미지의 참 함수 (feature와 label 사이의 실제 평균 관계이지만 실제 관측은 X)
- εi : 측정 오차

피처와 라벨의 관계를 잘 나타내는 함수 f를 찾기 위해서 어떤 함수가 가장 잘 맞는지 **학습**해야 함

### 학습 (Learning)
입력과 출력 관계를 찾는 과정으로, 평균 관계를 하나의 함수로 표현함

### 가설 공간 (Hypothesis Space)
관계를 표현할 수 있는 모든 후보 함수들의 모음, **피쳐 공간**과 **라벨 공간** 위에서 정의된 함수들의 집합 *F*

### 모델 (Model)
가설공간 *F*에 속한 특정 함수 𝑓

### 학습
주어진 **데이터**와 성능척도를 바탕으로 **가설공간**의 후보들 중 **최적의 모델**을 선택하는 과정 (데이터 D → 가설공간 *F* → 선택된 모델 𝑓)

---

### 2D 피쳐 기반 학습
ex) Income = 𝑓*(Years of Education, Seniority) + ε
피쳐가 2개 이상이니까 피쳐와 y값의 관계의 평균인 𝑓는 Surface가 됨

- 모델(함수형) : Y = 𝑓*(X) + ε
- 측정오차 ε : ε는 피쳐 X와 독립 및 E[ε]=0으로 가정함

---
## 지도학습 (supervised learning)
**입력(특성)** + **정답(레이블)** 을 가지고 예측 규칙을 배우는 방법.
- **회귀** : 예측값이 **숫자**(가격, 점수, 온도)
- **분류** : 예측값이 **범주**(스팸/정상, 질병 유무)

- **특성 (Feature, x)** : 예측에 쓰는 설명 변수
- **라벨 (Label, y)** : 맞춰야하는 정답
- **예측값 (ŷ)** : 모델이 내놓은 결과(숫자 또는 범주)
- **오류 (Error)** : 예측값(ŷ)과 라벨(y)의 차이 : ŷ-y

### 회귀(Regression) 문제

### 평균제곱오류 (Mean Squared Error)
각 데이터에서 정답 (yi)와 예측(ŷi)의 평균 제곱 차이값. 
- 큰 오류를 더 크게 벌줌(penalty)으로, 전체 오류 수준을 한눈에 봄.
- 데이터와 같은 단위 쓰고싶으면 RMSE (MSE의 제곱근) 사용

$$
\text{MSE} = \dfrac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

### 결정계수 ($R^2$)
라벨의 분산 중에서 특성으로 설명되는 비율. 얼마나 더 잘 맞추는지를 0~1 사이로 나타낸 값. **1에 가까울수록 설명력이 높고, 낮을수록 설명력이 낮음**

$$
R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}

$$
($\bar{y}$= $y_i$들의 평균값)


### 분류 정확도(Accuracy)
$$
\text{Accuracy} = \frac{1}{n} \sum_{i=1}^{n} \mathbf{II}(y_i = \hat{y}_i)
$$
($\mathbb{I}$: 지시함수, $\mathbb{I}(A)=1$ if A is true)

BUT 불균형데이터(양성 1%, 음성 99%)에서는 **전부 음성**이라 해도 정확도가 99%로 보일 수 있음 ! 
→ 다른 지표도 함께 봐야 함

### 혼동행렬 (Confusion Matrix)
- TP (실제 양성, 예측도 양성)
- TN (실제 음성, 예측도 음성)
- FP (실제 음성, 예측도 양성) → 오탐
- FN (실제 양성, 예측도 음성) → 누락

### 정밀도 (Precision)
양성이라 판정한 것 중 진짜 양성의 비율 `= TP / (TP+FP)`

### 재현율 (Sensitivity or Recall)
진짜 양성 가운데 잡아낸 에측 양성 비율 `= TP / (TP+FN)`

### F1-score
정밀도와 재현율의 조화평균
`F1 = 2 * (정밀도 * 재현율) / (정밀도 + 재현율)`

---
### 학습의 목적
학습 모델의 성능 평가는 모델이 **처음 보는 (학습에 사용되지않은) 데이터**로 평가 (→ 일반화 오류의 최소화 지향)
  
### 오버피팅 (overfitting)
훈련 데이터의 **우연한 패턴/잡음**까지 외워버려서 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상 → **훈련 오류 급격히 낮음**, 테스트 오류 **높음/요동**